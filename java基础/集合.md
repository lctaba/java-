## hashmap

1.7数组+链表

1.8数组+链表+红黑树

链表长度>8转为红黑树  数组长度>64

链表长度<=6退化为链表

hashmap扩容是2的次幂，因为这样做取模效率高（用与&取模）用1111与，这样算出来hash冲突较少。后来改为高16位与低16位异或，然后再取模。为的是保留所有位置的信息。不用&和|是因为&向0靠拢，|向1靠拢，异或能充分保留特征。

用Interger，String这种不可变的类当作Key，一般用String，因为String在创建的时候hashcode就已经被缓存了。

作为key的对象需要重写hashcode和equals方法

可变类作为key会导致hashcode发生变化，就get不出来

key和value都可以是null



自定义class作为hashmap的key

- 重写hashcode和equals
- 添加final修饰符，保证类不被继承。 
- 所有成员变量必须私有，并且加上final修饰
- 不提供改变成员变量的方法
- 通过构造器初始化所有成员，进⾏深拷⻉
- 在getter⽅法中，不要直接返回对象本⾝，⽽是克隆对象，并返回对象的拷⻉



去重：先比较hashcode，再比较equals



#### entry

就是一个包含了键值对的链表。



#### put操作先插入再扩容（1.7先扩容再插入）

为什么1.7先扩容再插入而1.8先插入再扩容？

1.7用头插法，先扩容后，插入只需插入头部，而1.8采用尾插法，先扩容后还得再遍历一遍，找到尾部进行插入。？有可能？



头插法的问题：扩容死循环。因为用头插法之后原来数据会反序，如果某个线程在resize的时候被挂起，而另一个线程仍然在进行resize操作，就导致原线程中的两个引用e和e.next反序，变成了e是e.next的next。如果重新扩容的话他就会死循环。

多线程不安全

## treeset

作为key的对象必须实现Comparable接口，否则无法比较，或者用自定义比较器。

底层就是treemap

去重原理：通过comparaTo比较，如果相等就是重复的



## treemap

实现了红黑树结构。





## LinkedHashMap

有插入顺序和访问顺序两种，插入顺序遍历是按插入的顺序遍历，访问顺序是按访问的顺序遍历